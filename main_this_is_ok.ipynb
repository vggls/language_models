{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vggls/language_models/blob/main/main_this_is_ok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d6956a",
      "metadata": {
        "id": "f9d6956a"
      },
      "source": [
        "### General imports for all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b7f5a2",
      "metadata": {
        "id": "11b7f5a2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import math\n",
        "#import string #string.punctuation contains punctuation symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BB5XpXe6SWiW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB5XpXe6SWiW",
        "outputId": "5b6ed359-c3e2-403f-f312-91481fdcb446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# for google colab import run this cell as well\n",
        "import nltk\n",
        "nltk.download('treebank')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tV-3ekEQRRsP",
      "metadata": {
        "id": "tV-3ekEQRRsP"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import treebank"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5812bcd0",
      "metadata": {
        "id": "5812bcd0"
      },
      "source": [
        "### A. 3-gram language model with Laplace smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f0bf54",
      "metadata": {
        "id": "84f0bf54"
      },
      "outputs": [],
      "source": [
        "# custom written code\n",
        "from preprocessing import lower, add_unk_tokens_for_training, replace_with_unk_for_testing, replace_doubleslash_token_with_unk, create_ngrams\n",
        "from laplace_model import count_n_grams, laplace_model, perplexity_ngram_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba7fbc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aba7fbc4",
        "outputId": "45cb0010-871f-4401-fb53-f9ba4e1a40ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3576, 338)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Penn Treebank\n",
        "symbols_to_remove = set(['-LRB-', '-RRB-', '-LSB-', '-RSB-', '-LCB-', '-RCB-'])\n",
        "\n",
        "train_treebank = []\n",
        "for j in range(175):\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "\n",
        "        # Remove tokens that contain '*' or are punctuation/symbols\n",
        "        l = [token for token in i if '*' not in token and token not in symbols_to_remove]\n",
        "\n",
        "        # Append the sentence to the training data\n",
        "        train_treebank.append(l)\n",
        "\n",
        "test_treebank = []\n",
        "for j in range(175, 199):\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [token for token in i if '*' not in token and token not in symbols_to_remove]\n",
        "        test_treebank.append(l)\n",
        "\n",
        "len(train_treebank), len(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e914c7",
      "metadata": {
        "id": "86e914c7"
      },
      "outputs": [],
      "source": [
        "#lower first letter of each token\n",
        "train_tokenized_sentences = lower(train_treebank)\n",
        "test_tokenized_sentences = lower(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799c8441",
      "metadata": {
        "id": "799c8441"
      },
      "outputs": [],
      "source": [
        "# insert <unk> token to training data\n",
        "train_tokenized_sentences = add_unk_tokens_for_training(train_tokenized_sentences) #replace all tokens that appear less than 3 times with <unk>\n",
        "train_tokenized_sentences = replace_doubleslash_token_with_unk(train_tokenized_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inspecting the resulting tokens, we observe that Penn Treebank comes with some bad-shaped tokens such as '1\\\\/4', '7\\\\/8', 'macmillan\\/mcgraw-hill', 'macmillan\\/mcgraw', '1\\\\/2' etc. In other words, tokens that include the sequence '\\/', which makes no sense. Thus we will replace tokens including this sequence with '< unk>' as well. From now on, we will refer to this tokens as 'slash' tokens."
      ],
      "metadata": {
        "id": "DSzYw6t0AVke"
      },
      "id": "DSzYw6t0AVke"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ad9dfc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ad9dfc",
        "outputId": "bd64de6f-0ca9-4c82-f946-b29a907a28a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3466"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#the vocabulary is useful for the testing phase\n",
        "vocabulary = set([item for sublist in train_tokenized_sentences for item in sublist])\n",
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c85adba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c85adba",
        "outputId": "5c75a5ed-91af-42fa-8f6a-a4d450b91260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "'<unk>' in vocabulary, '<bos>' in vocabulary, '<eos>' in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C6WXQ6T9ineR",
      "metadata": {
        "id": "C6WXQ6T9ineR"
      },
      "outputs": [],
      "source": [
        "# insert <unk> token to test data\n",
        "test_tokenized_sentences = replace_with_unk_for_testing(vocabulary, test_tokenized_sentences)\n",
        "test_tokenized_sentences = replace_doubleslash_token_with_unk(test_tokenized_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xGkUYXgmH5mQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGkUYXgmH5mQ",
        "outputId": "fcd31ad5-b001-4e81-946f-0658d655e6b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90526, 94102, 8663)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#add <bos> and <eos> tokens and compute ngrams\n",
        "train_bigrams = create_ngrams(2, train_tokenized_sentences)\n",
        "train_trigrams = create_ngrams(3, train_tokenized_sentences)\n",
        "test_trigrams = create_ngrams(3, test_tokenized_sentences)\n",
        "\n",
        "len(train_bigrams), len(train_trigrams), len(test_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45022c9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45022c9c",
        "outputId": "78ad3fe2-1bcb-4953-e837-33a0c9da937c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "['<unk>', '<unk>', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.'] \n",
            "\n",
            "[['<bos>', '<unk>'], ['<unk>', '<unk>'], ['<unk>', ','], [',', '61'], ['61', 'years'], ['years', 'old'], ['old', ','], [',', 'will'], ['will', 'join'], ['join', 'the'], ['the', 'board'], ['board', 'as'], ['as', 'a'], ['a', 'nonexecutive'], ['nonexecutive', 'director'], ['director', 'nov.']] \n",
            "\n",
            "[['<bos>', '<bos>', '<unk>'], ['<bos>', '<unk>', '<unk>'], ['<unk>', '<unk>', ','], ['<unk>', ',', '61'], [',', '61', 'years'], ['61', 'years', 'old'], ['years', 'old', ','], ['old', ',', 'will'], [',', 'will', 'join'], ['will', 'join', 'the'], ['join', 'the', 'board'], ['the', 'board', 'as'], ['board', 'as', 'a'], ['as', 'a', 'nonexecutive'], ['a', 'nonexecutive', 'director'], ['nonexecutive', 'director', 'nov.'], ['director', 'nov.', '29']]\n"
          ]
        }
      ],
      "source": [
        "#example of 2-grams and 3-grams extracted from the first training sentence\n",
        "print(train_treebank[0], '\\n')\n",
        "print(train_tokenized_sentences[0], '\\n')\n",
        "print(train_bigrams[:16], '\\n')\n",
        "print(train_trigrams[:17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a6d6f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91a6d6f0",
        "outputId": "acc51a81-e40d-4bfc-e78b-dd0c054d1b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Xerox', 'Corp.', 'has', 'told', 'employees', 'in', 'its', 'Crum', '&', 'Forster', 'personal', 'insurance', 'operations', 'that', 'it', 'is', 'laying', 'off', 'about', '300', 'people', ',', 'or', '25', '%', 'of', 'the', 'staff', '.'] \n",
            "\n",
            "['<unk>', 'corp.', 'has', 'told', 'employees', 'in', 'its', '<unk>', '&', '<unk>', 'personal', 'insurance', 'operations', 'that', 'it', 'is', '<unk>', 'off', 'about', '300', 'people', ',', 'or', '25', '%', 'of', 'the', 'staff', '.'] \n",
            "\n",
            "[['<bos>', '<bos>', '<unk>'], ['<bos>', '<unk>', 'corp.'], ['<unk>', 'corp.', 'has'], ['corp.', 'has', 'told'], ['has', 'told', 'employees'], ['told', 'employees', 'in'], ['employees', 'in', 'its'], ['in', 'its', '<unk>'], ['its', '<unk>', '&'], ['<unk>', '&', '<unk>'], ['&', '<unk>', 'personal'], ['<unk>', 'personal', 'insurance'], ['personal', 'insurance', 'operations'], ['insurance', 'operations', 'that'], ['operations', 'that', 'it'], ['that', 'it', 'is'], ['it', 'is', '<unk>'], ['is', '<unk>', 'off'], ['<unk>', 'off', 'about'], ['off', 'about', '300'], ['about', '300', 'people'], ['300', 'people', ','], ['people', ',', 'or'], [',', 'or', '25'], ['or', '25', '%'], ['25', '%', 'of'], ['%', 'of', 'the']]\n"
          ]
        }
      ],
      "source": [
        "#example of 3-grams extracted from the first test sentence\n",
        "print(test_treebank[0], '\\n')\n",
        "print(test_tokenized_sentences[0], '\\n')\n",
        "print(test_trigrams[:27])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d778d725",
      "metadata": {
        "id": "d778d725"
      },
      "outputs": [],
      "source": [
        "#2-grams and 3-grams frequencies\n",
        "bigrams_counts = count_n_grams(train_bigrams)\n",
        "trigrams_counts = count_n_grams(train_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ngrams_counts.pickle', 'wb') as f:\n",
        "        pickle.dump([bigrams_counts, trigrams_counts], f)"
      ],
      "metadata": {
        "id": "OUcSSiQgLq5D"
      },
      "id": "OUcSSiQgLq5D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gql3hv_vVIcU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gql3hv_vVIcU",
        "outputId": "8b0d8136-72da-41dd-b9c3-068cf04175f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1081.5835351523908"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "perplexity_ngram_model(nminus1_grams_counts=bigrams_counts,\n",
        "                       n_grams_counts=trigrams_counts,\n",
        "                       test_n_grams=test_trigrams,\n",
        "                       vocab_size=len(vocabulary))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d91ea29",
      "metadata": {
        "id": "8d91ea29"
      },
      "source": [
        "### B. LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ba18ac",
      "metadata": {
        "id": "55ba18ac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d41a1600",
      "metadata": {
        "id": "d41a1600"
      },
      "outputs": [],
      "source": [
        "#custom written code\n",
        "from preprocessing import lower, add_unk_tokens_for_training, unk_for_reduced_vocab, replace_doubleslash_token_with_unk, replace_with_unk_for_testing, tokens_to_indices\n",
        "from training import Train\n",
        "from lstm_model import LSTMModel\n",
        "from perplexity_neural import perplexity_neural_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca932ef4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca932ef4",
        "outputId": "0fad5433-af3b-455d-883a-1c0f0585f1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3262, 314, 338)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Penn Treebank\n",
        "\n",
        "def load_treebank(left_limit, right_limit):\n",
        "\n",
        "    symbols_to_remove = set(['-LRB-', '-RRB-', '-LSB-', '-RSB-', '-LCB-', '-RCB-'])\n",
        "\n",
        "    #sos_token = ['<bos>']\n",
        "    eos_token = ['<eos>']\n",
        "\n",
        "    tokenized_sentences = []\n",
        "    for j in range(left_limit, right_limit):\n",
        "        for i in treebank.sents(treebank.fileids()[j]):\n",
        "            l = [token for token in i if '*' not in token and token not in symbols_to_remove]\n",
        "            l = l + eos_token\n",
        "            tokenized_sentences.append(l)\n",
        "\n",
        "    return tokenized_sentences\n",
        "\n",
        "train_treebank = load_treebank(0, 150)\n",
        "val_treebank = load_treebank(150, 175)\n",
        "test_treebank = load_treebank(175, 199)\n",
        "\n",
        "len(train_treebank), len(val_treebank), len(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c3f077",
      "metadata": {
        "id": "80c3f077"
      },
      "outputs": [],
      "source": [
        "#lower first letter of each token - this is common for both cases\n",
        "lower_train_treebank = lower(train_treebank)\n",
        "lower_val_treebank = lower(val_treebank)\n",
        "lower_test_treebank = lower(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924e91fb",
      "metadata": {
        "id": "924e91fb"
      },
      "outputs": [],
      "source": [
        "# insert <unk> token to training data - this is common for both cases (but case II needs one additional transformation)\n",
        "train_sentences = add_unk_tokens_for_training(lower_train_treebank) #replace all tokens that appear less than 3 times with <unk>\n",
        "train_sentences = replace_doubleslash_token_with_unk(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820386ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820386ec",
        "outputId": "0c7625e3-ca24-44c0-dd62-d37b2a7531bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3259, True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#the vocabulary is useful for the testing phase - this is for case I only\n",
        "vocabulary = set([item for sublist in train_sentences for item in sublist])\n",
        "len(vocabulary), '<unk>' in vocabulary, '<eos>' in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model architecture hyperparams - common cell for both cases\n",
        "embedding_dim = 300\n",
        "num_layers = 2\n",
        "hidden_dim = 300\n",
        "dropout_rate = 0.3"
      ],
      "metadata": {
        "id": "zZwK1O9nv7xQ"
      },
      "id": "zZwK1O9nv7xQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### case I: model with learnable embeddings"
      ],
      "metadata": {
        "id": "Z12KumNdn827"
      },
      "id": "Z12KumNdn827"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8964f5a1",
      "metadata": {
        "id": "8964f5a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7711f2fe-0e27-454f-fd55-3d97362905d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1667, 2118)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# not the same index assignments every time i run the cell\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
        "word_to_index['<eos>'], word_to_index['<unk>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20c19a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d20c19a3",
        "outputId": "e687cedb-ec3b-4a8e-d454-57f4fca5f41e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82479, 8047, 8325)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# training sequence of indices\n",
        "train_int_sequence = tokens_to_indices(word_to_index, train_sentences)\n",
        "\n",
        "# validation sequence of indices\n",
        "val_sentences = replace_with_unk_for_testing(vocabulary, lower_val_treebank)\n",
        "val_sentences = replace_doubleslash_token_with_unk(val_sentences)\n",
        "val_int_sequence = tokens_to_indices(word_to_index, val_sentences)\n",
        "\n",
        "# testing sequence of indices\n",
        "test_sentences = replace_with_unk_for_testing(vocabulary, lower_test_treebank)\n",
        "test_sentences = replace_doubleslash_token_with_unk(test_sentences)\n",
        "test_int_sequence = tokens_to_indices(word_to_index, test_sentences)\n",
        "\n",
        "len(train_int_sequence), len(val_int_sequence), len(test_int_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(train_int_sequence)), len(set(val_int_sequence)), len(set(test_int_sequence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRDdI05dub1i",
        "outputId": "f77761ca-5ba0-43ad-f018-f77e8b7583e3"
      },
      "id": "NRDdI05dub1i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3259, 1165, 1272)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdf6726",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdf6726",
        "outputId": "5cc00ebd-937c-4844-8073-05ba6fcac162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<unk>', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.', '<eos>'] ['mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', ',', 'the', 'dutch', 'publishing', 'group', '.', '<eos>'] \n",
            "\n",
            "[2118, 2118, 19, 1371, 3158, 397, 19, 1701, 948, 2323, 174, 1843, 957, 1390, 879, 1496, 785, 3162, 1667, 2015, 2118, 262, 2345, 1861, 2118, 1365, 19, 2323]\n"
          ]
        }
      ],
      "source": [
        "# brief explanation how to feed a recurrent neural net\n",
        "# for simplicity, consider the case of the first two sentences\n",
        "print(train_sentences[0], train_sentences[1], '\\n')\n",
        "print(train_int_sequence[:28])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c8939d2",
      "metadata": {
        "id": "1c8939d2"
      },
      "source": [
        "In the above representation recall that '.' is represented by 2262 and the unknown word by 1855.\n",
        "\n",
        "So if we process the data in sequences of length = 5, the model will learn as follows:\n",
        "\n",
        "- map [1855, 1855, 1062, 419] to 1620\n",
        "- map [1855, 1062, 419, 1620] to 885\n",
        "- i.e. shift input by 1-step to the future and continue like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g8BTqgDDPjjX",
      "metadata": {
        "id": "g8BTqgDDPjjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb1e524-ebd7-46d7-9a91-3239b03993e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3259"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "vocab_size = len(vocabulary)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640ed70a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "640ed70a",
        "outputId": "c2fbbad2-3b91-46fc-f4de-5133697d042f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of trainable parameters: 2425759\n"
          ]
        }
      ],
      "source": [
        "# Create the model, loss function, and optimizer\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, True, None)\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'No. of trainable parameters: {num_params}')\n",
        "\n",
        "#model training hyperparams\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j5WVNxn_Wjog",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5WVNxn_Wjog",
        "outputId": "16c16022-8be3-4449-e11e-463a35747e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=train_int_sequence,\n",
        "                val_sequence=val_int_sequence,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=50,\n",
        "                patience=10,\n",
        "                name='lstm_with_learnable_embeddings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AAKQj9FLl_Xa",
      "metadata": {
        "id": "AAKQj9FLl_Xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db412cff-b31c-40e0-8be7-b1f7f4a4b835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training..\n",
            "Epoch: 1/50 - Perplexity: training 351.068, validation 147.867\n",
            "Epoch: 2/50 - Perplexity: training 215.300, validation 124.748 - E.S. checkpoint\n",
            "Epoch: 3/50 - Perplexity: training 170.749, validation 108.157 - E.S. checkpoint\n",
            "Epoch: 4/50 - Perplexity: training 139.524, validation 94.884 - E.S. checkpoint\n",
            "Epoch: 5/50 - Perplexity: training 120.880, validation 89.324 - E.S. checkpoint\n",
            "Epoch: 6/50 - Perplexity: training 101.748, validation 81.887 - E.S. checkpoint\n",
            "Epoch: 7/50 - Perplexity: training 85.870, validation 75.808 - E.S. checkpoint\n",
            "Epoch: 8/50 - Perplexity: training 73.522, validation 72.348 - E.S. checkpoint\n",
            "Epoch: 9/50 - Perplexity: training 62.855, validation 71.383 - E.S. checkpoint\n",
            "Epoch: 10/50 - Perplexity: training 54.470, validation 70.134 - E.S. checkpoint\n",
            "Epoch: 11/50 - Perplexity: training 47.239, validation 70.779\n",
            "Epoch: 12/50 - Perplexity: training 41.416, validation 70.907\n",
            "Epoch: 13/50 - Perplexity: training 36.625, validation 72.729\n",
            "Epoch: 14/50 - Perplexity: training 32.613, validation 73.337\n",
            "Epoch: 15/50 - Perplexity: training 28.745, validation 73.321\n",
            "Epoch: 16/50 - Perplexity: training 26.224, validation 75.245\n",
            "Epoch: 17/50 - Perplexity: training 23.387, validation 76.723\n",
            "Epoch: 18/50 - Perplexity: training 21.035, validation 80.824\n",
            "Epoch: 19/50 - Perplexity: training 19.162, validation 82.399\n",
            "Epoch: 20/50 - Perplexity: training 17.996, validation 83.643\n",
            "Training complete !\n"
          ]
        }
      ],
      "source": [
        "train_loss, val_loss, checkpoints = instance.training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XsLQ9M4736Bt",
      "metadata": {
        "id": "XsLQ9M4736Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8fa853-af14-4caf-a552-6acadec2ff91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Starting training..\n",
            "No validation data is used.\n",
            "Epoch: 1/10 - Perplexity: training 96.871\n",
            "Epoch: 2/10 - Perplexity: training 48.482\n",
            "Epoch: 3/10 - Perplexity: training 29.794\n",
            "Epoch: 4/10 - Perplexity: training 20.691\n",
            "Epoch: 5/10 - Perplexity: training 15.023\n",
            "Epoch: 6/10 - Perplexity: training 11.435\n",
            "Epoch: 7/10 - Perplexity: training 8.997\n",
            "Epoch: 8/10 - Perplexity: training 7.273\n",
            "Epoch: 9/10 - Perplexity: training 5.953\n",
            "Epoch: 10/10 - Perplexity: training 4.994\n",
            "Training complete !\n"
          ]
        }
      ],
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=val_int_sequence,\n",
        "                val_sequence=None,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=10,\n",
        "                patience=None,\n",
        "                name=None)\n",
        "\n",
        "train_loss_of_val_data = instance.training()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model_epoch10_lstm_with_learnable_embeddings.pth')"
      ],
      "metadata": {
        "id": "6NNVTsKSth10"
      },
      "id": "6NNVTsKSth10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SXb8QVJfDKMc",
      "metadata": {
        "id": "SXb8QVJfDKMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3920df-ec89-48b9-b295-c95dfce1a321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163.55122742221675"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "perplexity_neural_model(test_sequence_of_integers = test_int_sequence,\n",
        "                        sequence_length = 50,\n",
        "                        model = model,\n",
        "                        loss_fct = nn.CrossEntropyLoss(),\n",
        "                        vocab_size = len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8w-Xug5efKwP",
      "metadata": {
        "id": "8w-Xug5efKwP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "FMioYyfHQLFp",
      "metadata": {
        "id": "FMioYyfHQLFp"
      },
      "source": [
        "#### case II: model with pre-trained GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6iDwGHocxEbX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iDwGHocxEbX",
        "outputId": "81f842c7-81b2-46f6-a8b1-058e7acf3af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EVUA2QHuxEeV",
      "metadata": {
        "id": "EVUA2QHuxEeV"
      },
      "outputs": [],
      "source": [
        "# Load GloVe 300-dim embeddings into word_embeddings dictionary\n",
        "import os\n",
        "\n",
        "glove_dir ='/content/drive/MyDrive/Colab_Notebooks/language_models'\n",
        "\n",
        "word_embeddings = {} # dictionary with (word, embedding) items\n",
        "\n",
        "with open(os.path.join(glove_dir, 'glove.6B.300d.txt')) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        embedding = torch.tensor([float(val) for val in values[1:]])\n",
        "        word_embeddings[word] = embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do GloVe embeddings have representations for all tokens in the vocabulary?\n",
        "intersection = set(word_embeddings.keys()) & vocabulary\n",
        "words_not_in_glove = vocabulary - intersection\n",
        "len(words_not_in_glove) #'<unk>', '<eos>' included"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymlO5QYnULuA",
        "outputId": "46c76c7b-217f-4d82-bf0b-d2538a37df77"
      },
      "id": "ymlO5QYnULuA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to deal with words_without_glove_representation ?\n",
        "# One approach, is to assign them to the '<unk>' token. This results in a reduced vocabulary.\n",
        "\n",
        "reduced_vocabulary = vocabulary - words_not_in_glove\n",
        "reduced_vocabulary.add('<unk>')\n",
        "reduced_vocabulary.add('<eos>')\n",
        "\n",
        "assert len(reduced_vocabulary) == len(vocabulary) - len(words_not_in_glove) + 2 # 3225 = 3259 - 36 + 2"
      ],
      "metadata": {
        "id": "gXO_8eZVnCl8"
      },
      "id": "gXO_8eZVnCl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we also replace with <unk> train_sentences tokens that are not included in the reduced_vocabulary\n",
        "train_sentences = unk_for_reduced_vocab(train_sentences, reduced_vocabulary)"
      ],
      "metadata": {
        "id": "mKmkfvvKqazx"
      },
      "id": "mKmkfvvKqazx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not the same index assignments every time i run the cell\n",
        "word_to_index = {word: idx for idx, word in enumerate(reduced_vocabulary)}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}"
      ],
      "metadata": {
        "id": "AcS9o6sLqa4H"
      },
      "id": "AcS9o6sLqa4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unk_index = word_to_index['<unk>']\n",
        "eos_index = word_to_index['<eos>']"
      ],
      "metadata": {
        "id": "nlmYXayAu99i"
      },
      "id": "nlmYXayAu99i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training sequence of indices\n",
        "train_int_sequence = tokens_to_indices(word_to_index, train_sentences)\n",
        "\n",
        "# validation sequence of indices\n",
        "val_sentences = replace_with_unk_for_testing(reduced_vocabulary, lower_val_treebank)\n",
        "val_sentences = replace_doubleslash_token_with_unk(val_sentences)\n",
        "val_int_sequence = tokens_to_indices(word_to_index, val_sentences)\n",
        "\n",
        "# testing sequence of indices\n",
        "test_sentences = replace_with_unk_for_testing(reduced_vocabulary, lower_test_treebank)\n",
        "test_sentences = replace_doubleslash_token_with_unk(test_sentences)\n",
        "test_int_sequence = tokens_to_indices(word_to_index, test_sentences)\n",
        "\n",
        "len(train_int_sequence), len(val_int_sequence), len(test_int_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x47fWPrVqa6w",
        "outputId": "72979045-60f3-4745-8300-3f1d05711b32"
      },
      "id": "x47fWPrVqa6w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82479, 8047, 8325)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(train_int_sequence)), len(set(val_int_sequence)), len(set(test_int_sequence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeUyBWovuw2z",
        "outputId": "f097495a-61a3-4254-9bad-4f87426a03c0"
      },
      "id": "QeUyBWovuw2z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3225, 1160, 1269)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create embedding layer weights\n",
        "\n",
        "reduced_vocab_size = len(reduced_vocabulary)\n",
        "embeddings = torch.zeros(reduced_vocab_size, embedding_dim)\n",
        "\n",
        "# put the glove embeddings in the embeddings matrix\n",
        "for (word, index) in word_to_index.items():\n",
        "    if word not in ['<unk>', '<eos>']:\n",
        "        embeddings[index] = word_embeddings[word]\n",
        "\n",
        "all_vectors = list(word_embeddings.values())\n",
        "embeddings[eos_index] = torch.mean(torch.stack(all_vectors), dim=0)\n",
        "\n",
        "embeddings[unk_index] = torch.rand(embedding_dim)"
      ],
      "metadata": {
        "id": "qI2SEqyaqa9K"
      },
      "id": "qI2SEqyaqa9K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_vocab_size = len(reduced_vocabulary)"
      ],
      "metadata": {
        "id": "EDRJX9WCqbLv"
      },
      "id": "EDRJX9WCqbLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ae-cz8b9hSPs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae-cz8b9hSPs",
        "outputId": "67bae61a-db7d-454e-d5af-3c063117465d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of trainable parameters: 2415525\n"
          ]
        }
      ],
      "source": [
        "# Create the model, loss function, and optimizer\n",
        "model = LSTMModel(reduced_vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, True, embeddings)\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'No. of trainable parameters: {num_params}')\n",
        "\n",
        "#model training hyperparams\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=train_int_sequence,\n",
        "                val_sequence=val_int_sequence,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=50,\n",
        "                patience=10,\n",
        "                name='lstm_with_glove_embeddings')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCrWE-q5dbD",
        "outputId": "7c63fa4d-2952-4435-ed15-c6f5aa44baf9"
      },
      "id": "hFCrWE-q5dbD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss, checkpoints = instance.training()"
      ],
      "metadata": {
        "id": "5WxYLaew5ddy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15841498-da1c-4772-f363-c2c58046f1e5"
      },
      "id": "5WxYLaew5ddy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training..\n",
            "Epoch: 1/50 - Perplexity: training 339.894, validation 148.184\n",
            "Epoch: 2/50 - Perplexity: training 196.740, validation 117.196 - E.S. checkpoint\n",
            "Epoch: 3/50 - Perplexity: training 158.067, validation 102.477 - E.S. checkpoint\n",
            "Epoch: 4/50 - Perplexity: training 132.385, validation 92.065 - E.S. checkpoint\n",
            "Epoch: 5/50 - Perplexity: training 114.328, validation 86.670 - E.S. checkpoint\n",
            "Epoch: 6/50 - Perplexity: training 99.596, validation 82.106 - E.S. checkpoint\n",
            "Epoch: 7/50 - Perplexity: training 88.072, validation 80.030 - E.S. checkpoint\n",
            "Epoch: 8/50 - Perplexity: training 78.478, validation 77.840 - E.S. checkpoint\n",
            "Epoch: 9/50 - Perplexity: training 70.121, validation 76.481 - E.S. checkpoint\n",
            "Epoch: 10/50 - Perplexity: training 63.404, validation 75.352 - E.S. checkpoint\n",
            "Epoch: 11/50 - Perplexity: training 56.756, validation 74.600 - E.S. checkpoint\n",
            "Epoch: 12/50 - Perplexity: training 51.132, validation 74.997\n",
            "Epoch: 13/50 - Perplexity: training 46.583, validation 75.363\n",
            "Epoch: 14/50 - Perplexity: training 42.476, validation 75.480\n",
            "Epoch: 15/50 - Perplexity: training 38.405, validation 75.988\n",
            "Epoch: 16/50 - Perplexity: training 35.011, validation 77.313\n",
            "Epoch: 17/50 - Perplexity: training 31.715, validation 78.128\n",
            "Epoch: 18/50 - Perplexity: training 29.311, validation 79.554\n",
            "Epoch: 19/50 - Perplexity: training 27.322, validation 81.536\n",
            "Epoch: 20/50 - Perplexity: training 24.922, validation 82.869\n",
            "Epoch: 21/50 - Perplexity: training 22.990, validation 85.027\n",
            "Training complete !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=val_int_sequence,\n",
        "                val_sequence=None,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=11,\n",
        "                patience=None,\n",
        "                name=None)\n",
        "\n",
        "train_loss_of_val_data = instance.training()"
      ],
      "metadata": {
        "id": "DBwRXLR15dg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a82bffd7-a0ac-434a-9de7-a8d799f5054d"
      },
      "id": "DBwRXLR15dg3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n",
            "Starting training..\n",
            "No validation data is used.\n",
            "Epoch: 1/11 - Perplexity: training 92.324\n",
            "Epoch: 2/11 - Perplexity: training 52.651\n",
            "Epoch: 3/11 - Perplexity: training 35.740\n",
            "Epoch: 4/11 - Perplexity: training 26.891\n",
            "Epoch: 5/11 - Perplexity: training 21.224\n",
            "Epoch: 6/11 - Perplexity: training 16.992\n",
            "Epoch: 7/11 - Perplexity: training 14.254\n",
            "Epoch: 8/11 - Perplexity: training 11.996\n",
            "Epoch: 9/11 - Perplexity: training 10.256\n",
            "Epoch: 10/11 - Perplexity: training 9.004\n",
            "Epoch: 11/11 - Perplexity: training 7.762\n",
            "Training complete !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model_epoch11_lstm_with_glove_embeddings.pth')"
      ],
      "metadata": {
        "id": "EBWLU7pOx-rn"
      },
      "id": "EBWLU7pOx-rn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_neural_model(test_sequence_of_integers = test_int_sequence,\n",
        "                        sequence_length = 50,\n",
        "                        model = model,\n",
        "                        loss_fct = nn.CrossEntropyLoss(),\n",
        "                        vocab_size = len(reduced_vocabulary))"
      ],
      "metadata": {
        "id": "qKbp_zGl5dja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14af3590-6fcc-48ee-eaee-db39635847e3"
      },
      "id": "qKbp_zGl5dja",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.90886196455799"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pty5FGljvOyt"
      },
      "id": "pty5FGljvOyt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da2fd2ac",
      "metadata": {
        "id": "da2fd2ac"
      },
      "source": [
        "### C. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9d9c82",
      "metadata": {
        "id": "eb9d9c82"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db639c2",
      "metadata": {
        "id": "4db639c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a6c501",
      "metadata": {
        "id": "81a6c501"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "72762156",
      "metadata": {
        "id": "72762156"
      },
      "source": [
        "### D. Comparisons & Text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c9b5fe",
      "metadata": {
        "id": "b3c9b5fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8ebf1f",
      "metadata": {
        "id": "4f8ebf1f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "f9d6956a",
        "5812bcd0",
        "da2fd2ac",
        "72762156"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}