{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d6956a",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b7f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vangelis\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341c81f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom written code\n",
    "\n",
    "from ngrams import add_unk_tokens, training_ngrams, test_ngrams #for laplace model\n",
    "from laplace_model import laplace_model\n",
    "from perplexity import perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5812bcd0",
   "metadata": {},
   "source": [
    "#### Penn Treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba7fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_treebank = []\n",
    "for j in range(150): # len(treebank.fileids()) = 199\n",
    "    for i in treebank.sents(treebank.fileids()[j]):\n",
    "        l = [j for j in i if '*' not in j] # remove tokens that contain '*'\n",
    "        train_treebank.append(l)\n",
    "\n",
    "test_treebank = []\n",
    "for j in range(150, 199): # len(treebank.fileids()) = 199\n",
    "    for i in treebank.sents(treebank.fileids()[j]):\n",
    "        l = [j for j in i if '*' not in j]\n",
    "        test_treebank.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8194f75",
   "metadata": {},
   "source": [
    "#### 3-gram language model with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e914c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [sentence.copy() for sentence in train_treebank]\n",
    "test_sentences = [sentence.copy() for sentence in test_treebank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "799c8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all tokens that appear less than 3 times with <UNK>\n",
    "train_sentences = add_unk_tokens(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ad9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the vocabulary is useful for the testing phase\n",
    "vocabulary = set([item for sublist in train_sentences for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e762f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training 3-grams\n",
    "train_trigrams = training_ngrams(3, train_sentences)\n",
    "\n",
    "#test 3-grams - tokens not included in the vocabulary are replaced by <UNK>\n",
    "test_trigrams = test_ngrams(vocabulary, 3, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01af8d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85951, 14452)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trigrams), len(test_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45022c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "['<UNK>', '<UNK>', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
      "\n",
      "[['<BOS>', '<BOS>', '<UNK>'], ['<BOS>', '<UNK>', '<UNK>'], ['<UNK>', '<UNK>', ','], ['<UNK>', ',', '61'], [',', '61', 'years'], ['61', 'years', 'old'], ['years', 'old', ','], ['old', ',', 'will'], [',', 'will', 'join'], ['will', 'join', 'the'], ['join', 'the', 'board'], ['the', 'board', 'as'], ['board', 'as', 'a'], ['as', 'a', 'nonexecutive'], ['a', 'nonexecutive', 'director'], ['nonexecutive', 'director', 'Nov.'], ['director', 'Nov.', '29'], ['Nov.', '29', '.'], ['29', '.', '<EOS>'], ['.', '<EOS>', '<EOS>']]\n"
     ]
    }
   ],
   "source": [
    "#example of the 3-grams extracted from the first training sentence\n",
    "print(train_treebank[0], '\\n')\n",
    "print(train_sentences[0], '\\n')\n",
    "print(train_trigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91a6d6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intelogic', 'Trace', 'Inc.', ',', 'San', 'Antonio', ',', 'Texas', ',', 'said', '0', 'it', 'bought', '2.7', 'million', 'shares', ',', 'or', 'about', '18', '%', ',', 'of', 'its', 'common', 'stock', 'from', 'an', 'unaffiliated', 'shareholder', 'for', '$', '3.625', 'a', 'share', ',', 'or', '$', '9.9', 'million', '.'] \n",
      "\n",
      "['<UNK>', '<UNK>', 'Inc.', ',', 'San', '<UNK>', ',', 'Texas', ',', 'said', '0', 'it', 'bought', '<UNK>', 'million', 'shares', ',', 'or', 'about', '18', '%', ',', 'of', 'its', 'common', 'stock', 'from', 'an', '<UNK>', 'shareholder', 'for', '$', '<UNK>', 'a', 'share', ',', 'or', '$', '<UNK>', 'million', '.'] \n",
      "\n",
      "[['<UNK>', '<UNK>', 'Inc.'], ['<UNK>', 'Inc.', ','], ['Inc.', ',', 'San'], [',', 'San', '<UNK>'], ['San', '<UNK>', ','], ['<UNK>', ',', 'Texas'], [',', 'Texas', ','], ['Texas', ',', 'said'], [',', 'said', '0'], ['said', '0', 'it'], ['0', 'it', 'bought'], ['it', 'bought', '<UNK>'], ['bought', '<UNK>', 'million'], ['<UNK>', 'million', 'shares'], ['million', 'shares', ','], ['shares', ',', 'or'], [',', 'or', 'about'], ['or', 'about', '18'], ['about', '18', '%'], ['18', '%', ','], ['%', ',', 'of'], [',', 'of', 'its'], ['of', 'its', 'common'], ['its', 'common', 'stock'], ['common', 'stock', 'from'], ['stock', 'from', 'an'], ['from', 'an', '<UNK>'], ['an', '<UNK>', 'shareholder'], ['<UNK>', 'shareholder', 'for'], ['shareholder', 'for', '$'], ['for', '$', '<UNK>'], ['$', '<UNK>', 'a'], ['<UNK>', 'a', 'share'], ['a', 'share', ','], ['share', ',', 'or'], [',', 'or', '$'], ['or', '$', '<UNK>'], ['$', '<UNK>', 'million'], ['<UNK>', 'million', '.']]\n"
     ]
    }
   ],
   "source": [
    "#example of the 3-grams extracted from the first training sentence\n",
    "print(test_treebank[0], '\\n')\n",
    "print(test_sentences[0], '\\n')\n",
    "print(test_trigrams[:39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a34579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "laplace_learned_probs, laplace_unseen_prob = laplace_model(train_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68edded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('laplace_model.pickle', 'wb') as f:\n",
    "        pickle.dump([laplace_learned_probs, laplace_unseen_prob], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce0dd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_perplexity = perplexity(learned_distribution = laplace_learned_probs,\n",
    "                               unseen_prob = laplace_unseen_prob,\n",
    "                               ngrams = test_trigrams,\n",
    "                               N = len(test_treebank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6934b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.065682401595497e+32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplace_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778d725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d9c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
