{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vggls/language_models/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9d6956a",
      "metadata": {
        "id": "f9d6956a"
      },
      "source": [
        "### General imports for all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11b7f5a2",
      "metadata": {
        "id": "11b7f5a2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for google colab import run this cell as well\n",
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB5XpXe6SWiW",
        "outputId": "8cd9c1b5-7035-4a11-8ca6-7acb7e7d1022"
      },
      "id": "BB5XpXe6SWiW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import treebank"
      ],
      "metadata": {
        "id": "tV-3ekEQRRsP"
      },
      "id": "tV-3ekEQRRsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5812bcd0",
      "metadata": {
        "id": "5812bcd0"
      },
      "source": [
        "### 3-gram language model with Laplace smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f0bf54",
      "metadata": {
        "id": "84f0bf54"
      },
      "outputs": [],
      "source": [
        "# custom written code\n",
        "from preprocessing import lower, add_unk_tokens_for_training, replace_with_unk_for_testing, create_ngrams\n",
        "from laplace_model import count_n_grams, laplace_model, perplexity_ngram_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba7fbc4",
      "metadata": {
        "id": "aba7fbc4",
        "outputId": "b5b6d44b-be61-49b1-a926-20a5e559c57d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3576, 338)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Penn Treebank\n",
        "train_treebank = []\n",
        "for j in range(175): # len(treebank.fileids()) = 199\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [j for j in i if '*' not in j] # remove tokens that contain '*'\n",
        "        train_treebank.append(l)\n",
        "\n",
        "test_treebank = []\n",
        "for j in range(175, 199):\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [j for j in i if '*' not in j]\n",
        "        test_treebank.append(l)\n",
        "\n",
        "len(train_treebank), len(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e914c7",
      "metadata": {
        "id": "86e914c7"
      },
      "outputs": [],
      "source": [
        "#lower first letter of each token\n",
        "train_tokenized_sentences = lower(train_treebank)\n",
        "test_tokenized_sentences = lower(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "799c8441",
      "metadata": {
        "id": "799c8441"
      },
      "outputs": [],
      "source": [
        "# replace all tokens that appear less than 3 times with <unk>\n",
        "train_tokenized_sentences = add_unk_tokens_for_training(train_tokenized_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ad9dfc",
      "metadata": {
        "id": "45ad9dfc",
        "outputId": "16874a00-ebf2-48f8-ae62-8f5a4ed9efd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#the vocabulary is useful for the testing phase\n",
        "vocabulary = set([item for sublist in train_tokenized_sentences for item in sublist])\n",
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c85adba",
      "metadata": {
        "id": "7c85adba",
        "outputId": "2f1d20b6-86b9-44e3-d906-c89aa0bba419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, False, False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "'<unk>' in vocabulary, '<bos>' in vocabulary, '<eos>' in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tokenized_sentences = replace_with_unk_for_testing(vocabulary, test_tokenized_sentences)"
      ],
      "metadata": {
        "id": "C6WXQ6T9ineR"
      },
      "id": "C6WXQ6T9ineR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute ngrams\n",
        "train_bigrams = create_ngrams(2, train_tokenized_sentences)\n",
        "train_trigrams = create_ngrams(3, train_tokenized_sentences)\n",
        "test_trigrams = create_ngrams(3, test_tokenized_sentences)\n",
        "\n",
        "len(train_bigrams), len(train_trigrams), len(test_trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGkUYXgmH5mQ",
        "outputId": "2029c98c-5dcb-47d4-8010-837cb0a703d2"
      },
      "id": "xGkUYXgmH5mQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90748, 94324, 8687)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45022c9c",
      "metadata": {
        "id": "45022c9c",
        "outputId": "efd307b8-1468-4872-cdc1-9528ff32331d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "['<unk>', '<unk>', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.'] \n",
            "\n",
            "[['<bos>', '<unk>'], ['<unk>', '<unk>'], ['<unk>', ','], [',', '61'], ['61', 'years'], ['years', 'old'], ['old', ','], [',', 'will'], ['will', 'join'], ['join', 'the'], ['the', 'board'], ['board', 'as'], ['as', 'a'], ['a', 'nonexecutive'], ['nonexecutive', 'director'], ['director', 'nov.'], ['nov.', '29'], ['29', '.'], ['.', '<eos>']] \n",
            "\n",
            "[['<bos>', '<bos>', '<unk>'], ['<bos>', '<unk>', '<unk>'], ['<unk>', '<unk>', ','], ['<unk>', ',', '61'], [',', '61', 'years'], ['61', 'years', 'old'], ['years', 'old', ','], ['old', ',', 'will'], [',', 'will', 'join'], ['will', 'join', 'the'], ['join', 'the', 'board'], ['the', 'board', 'as'], ['board', 'as', 'a'], ['as', 'a', 'nonexecutive'], ['a', 'nonexecutive', 'director'], ['nonexecutive', 'director', 'nov.'], ['director', 'nov.', '29'], ['nov.', '29', '.'], ['29', '.', '<eos>'], ['.', '<eos>', '<eos>']]\n"
          ]
        }
      ],
      "source": [
        "#example of 2-grams and 3-grams extracted from the first training sentence\n",
        "print(train_treebank[0], '\\n')\n",
        "print(train_tokenized_sentences[0], '\\n')\n",
        "print(train_bigrams[:19], '\\n')\n",
        "print(train_trigrams[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a6d6f0",
      "metadata": {
        "id": "91a6d6f0",
        "outputId": "cf85d4f5-3146-4b3b-d306-836842e9e286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Xerox', 'Corp.', 'has', 'told', 'employees', 'in', 'its', 'Crum', '&', 'Forster', 'personal', 'insurance', 'operations', 'that', 'it', 'is', 'laying', 'off', 'about', '300', 'people', ',', 'or', '25', '%', 'of', 'the', 'staff', '.'] \n",
            "\n",
            "['<unk>', 'corp.', 'has', 'told', 'employees', 'in', 'its', '<unk>', '&', '<unk>', 'personal', 'insurance', 'operations', 'that', 'it', 'is', '<unk>', 'off', 'about', '300', 'people', ',', 'or', '25', '%', 'of', 'the', 'staff', '.'] \n",
            "\n",
            "[['<bos>', '<bos>', '<unk>'], ['<bos>', '<unk>', 'corp.'], ['<unk>', 'corp.', 'has'], ['corp.', 'has', 'told'], ['has', 'told', 'employees'], ['told', 'employees', 'in'], ['employees', 'in', 'its'], ['in', 'its', '<unk>'], ['its', '<unk>', '&'], ['<unk>', '&', '<unk>'], ['&', '<unk>', 'personal'], ['<unk>', 'personal', 'insurance'], ['personal', 'insurance', 'operations'], ['insurance', 'operations', 'that'], ['operations', 'that', 'it'], ['that', 'it', 'is'], ['it', 'is', '<unk>'], ['is', '<unk>', 'off'], ['<unk>', 'off', 'about'], ['off', 'about', '300'], ['about', '300', 'people'], ['300', 'people', ','], ['people', ',', 'or'], [',', 'or', '25'], ['or', '25', '%'], ['25', '%', 'of'], ['%', 'of', 'the'], ['of', 'the', 'staff'], ['the', 'staff', '.'], ['staff', '.', '<eos>'], ['.', '<eos>', '<eos>']]\n"
          ]
        }
      ],
      "source": [
        "#example of 3-grams extracted from the first test sentence\n",
        "print(test_treebank[0], '\\n')\n",
        "print(test_tokenized_sentences[0], '\\n')\n",
        "print(test_trigrams[:31])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d778d725",
      "metadata": {
        "id": "d778d725"
      },
      "outputs": [],
      "source": [
        "#2-grams and 3-grams frequencies\n",
        "bigrams_counts = count_n_grams(train_bigrams)\n",
        "trigrams_counts = count_n_grams(train_trigrams)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_ngram_model(nminus1_grams_counts=bigrams_counts,\n",
        "                       n_grams_counts=trigrams_counts,\n",
        "                       test_n_grams=test_trigrams,\n",
        "                       vocab_size=len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gql3hv_vVIcU",
        "outputId": "339a5663-0e5b-4082-e0cf-f5d70157120d"
      },
      "id": "Gql3hv_vVIcU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1091.699679451341"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d91ea29",
      "metadata": {
        "id": "8d91ea29"
      },
      "source": [
        "### LSTM language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ba18ac",
      "metadata": {
        "id": "55ba18ac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d41a1600",
      "metadata": {
        "id": "d41a1600"
      },
      "outputs": [],
      "source": [
        "#custom written code\n",
        "from preprocessing import lower, add_unk_tokens_for_training, replace_with_unk_for_testing, tokens_to_indices\n",
        "from training import Train\n",
        "from lstm_model import LSTMModel\n",
        "from perplexity_neural import perplexity_neural_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca932ef4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca932ef4",
        "outputId": "c53d0a2f-cdf7-4263-a154-f7c3e37fa04b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3262, 314, 338)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Penn Treebank\n",
        "train_treebank = []\n",
        "for j in range(150): # len(treebank.fileids()) = 199\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [j for j in i if '*' not in j] # remove tokens that contain '*'\n",
        "        train_treebank.append(l)\n",
        "\n",
        "val_treebank = []\n",
        "for j in range(150, 175): # len(treebank.fileids()) = 199\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [j for j in i if '*' not in j] # remove tokens that contain '*'\n",
        "        val_treebank.append(l)\n",
        "\n",
        "test_treebank = []\n",
        "for j in range(175, 199):\n",
        "    for i in treebank.sents(treebank.fileids()[j]):\n",
        "        l = [j for j in i if '*' not in j]\n",
        "        test_treebank.append(l)\n",
        "\n",
        "len(train_treebank), len(val_treebank), len(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c3f077",
      "metadata": {
        "id": "80c3f077"
      },
      "outputs": [],
      "source": [
        "#lower first letter of each token\n",
        "train_tokenized_sentences = lower(train_treebank)\n",
        "val_tokenized_sentences = lower(val_treebank)\n",
        "test_tokenized_sentences = lower(test_treebank)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924e91fb",
      "metadata": {
        "id": "924e91fb"
      },
      "outputs": [],
      "source": [
        "# replace all tokens that appear less than 3 times with <UNK>\n",
        "train_tokenized_sentences = add_unk_tokens_for_training(train_tokenized_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76060004",
      "metadata": {
        "id": "76060004"
      },
      "source": [
        "The vocabulary is constructed by the training data only. Note that the training data is different between the 3-gram and the lstm model, because the later one needs validation as well (in order to hyper-tune; note that the 3-gram model is unique). Since the test set will be the same for all models, for the lstm model we use as training set the largest part of the 3-gram model training set and the remaining small part as validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820386ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820386ec",
        "outputId": "4023099c-4722-4a91-8f99-643174634e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3273"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#the vocabulary is useful for the testing phase\n",
        "vocabulary = set([item for sublist in train_tokenized_sentences for item in sublist])\n",
        "len(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f15ee84",
      "metadata": {
        "id": "6f15ee84"
      },
      "outputs": [],
      "source": [
        "#Insert <EOS> token in the vocabulary? see source argument at the respective \"Vocabulary\" section\n",
        "# BUT in my case I have included \".\", whereas they do not. So, can i say that \".\" plays the role of \"<EOS>\"? Why not?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8964f5a1",
      "metadata": {
        "id": "8964f5a1"
      },
      "outputs": [],
      "source": [
        "# not the same index assignments every time i run the cell\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f69823",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20f69823",
        "outputId": "2749ae36-fb56-4342-d1cc-ef131433f070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2097, 616)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "word_to_index['.'], word_to_index['<unk>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20c19a3",
      "metadata": {
        "id": "d20c19a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e4d6e4-9442-4aa4-f005-17e2b5d20ee6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79427, 7745, 8011)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# training\n",
        "train_sequence = tokens_to_indices(word_to_index, train_tokenized_sentences)\n",
        "\n",
        "# validation\n",
        "val_tokenized_sentences = replace_with_unk_for_testing(vocabulary, val_tokenized_sentences)\n",
        "val_sequence = tokens_to_indices(word_to_index, val_tokenized_sentences)\n",
        "\n",
        "# testing\n",
        "test_tokenized_sentences = replace_with_unk_for_testing(vocabulary, test_tokenized_sentences)\n",
        "test_sequence = tokens_to_indices(word_to_index, test_tokenized_sentences)\n",
        "\n",
        "len(train_sequence), len(val_sequence), len(test_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efdf6726",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdf6726",
        "outputId": "c0ecb043-c676-4539-c693-494be93732fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<unk>', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.'] ['mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', ',', 'the', 'dutch', 'publishing', 'group', '.'] \n",
            "\n",
            "[616, 616, 1495, 2981, 1118, 2085, 1495, 1742, 551, 1285, 704, 330, 2939, 680, 391, 1910, 3254, 2097, 1282, 616, 1288, 998, 2384, 616, 2878, 1495, 1285, 803, 3229, 2616, 2097]\n"
          ]
        }
      ],
      "source": [
        "# brief explanation how to feed a recurrent neural net\n",
        "# for simplicity, consider the case of the first two sentences\n",
        "print(train_tokenized_sentences[0], train_tokenized_sentences[1], '\\n')\n",
        "print(train_sequence[:31])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c8939d2",
      "metadata": {
        "id": "1c8939d2"
      },
      "source": [
        "In the above representation recall that '.' is represented by 2262 and the unknown word by 1855.\n",
        "\n",
        "So if we process the data in sequences of length = 5, the model will learn as follows:\n",
        "\n",
        "- map [1855, 1855, 1062, 419] to 1620\n",
        "- map [1855, 1062, 419, 1620] to 885\n",
        "- i.e. shift input by 1-step to the future and continue like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640ed70a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "640ed70a",
        "outputId": "ce8d905a-0b93-4cd6-e41c-310c85b9730e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of trainable parameters: 1893833\n"
          ]
        }
      ],
      "source": [
        "#model architecture hyperparams\n",
        "vocab_size = len(vocabulary)\n",
        "embedding_dim = 256\n",
        "num_layers = 2\n",
        "hidden_dim = 256\n",
        "output_dim = vocab_size\n",
        "dropout_rate = 0.3\n",
        "\n",
        "#model training hyperparams\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create the model, loss function, and optimizer\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, num_layers, dropout_rate, True)\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'No. of trainable parameters: {num_params}')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=train_sequence,\n",
        "                val_sequence=val_sequence,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=50,\n",
        "                patience=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5WVNxn_Wjog",
        "outputId": "b2d529e2-32c4-4f4f-dc59-5c388ea17797"
      },
      "id": "j5WVNxn_Wjog",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, val_loss, checkpoints = instance.training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAKQj9FLl_Xa",
        "outputId": "08e6eeca-c0e6-4205-ce40-8746de8cc05b"
      },
      "id": "AAKQj9FLl_Xa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training..\n",
            "Epoch: 1/50 - Perplexity: training 436.930, validation 199.241\n",
            "Epoch: 2/50 - Perplexity: training 273.212, validation 160.250 - E.S. checkpoint\n",
            "Epoch: 3/50 - Perplexity: training 222.196, validation 141.705 - E.S. checkpoint\n",
            "Epoch: 4/50 - Perplexity: training 184.109, validation 125.460 - E.S. checkpoint\n",
            "Epoch: 5/50 - Perplexity: training 154.708, validation 114.497 - E.S. checkpoint\n",
            "Epoch: 6/50 - Perplexity: training 133.885, validation 107.699 - E.S. checkpoint\n",
            "Epoch: 7/50 - Perplexity: training 117.756, validation 101.582 - E.S. checkpoint\n",
            "Epoch: 8/50 - Perplexity: training 104.071, validation 99.292 - E.S. checkpoint\n",
            "Epoch: 9/50 - Perplexity: training 92.353, validation 96.590 - E.S. checkpoint\n",
            "Epoch: 10/50 - Perplexity: training 82.571, validation 94.993 - E.S. checkpoint\n",
            "Epoch: 11/50 - Perplexity: training 74.300, validation 94.294 - E.S. checkpoint\n",
            "Epoch: 12/50 - Perplexity: training 67.332, validation 93.491 - E.S. checkpoint\n",
            "Epoch: 13/50 - Perplexity: training 61.822, validation 92.887 - E.S. checkpoint\n",
            "Epoch: 14/50 - Perplexity: training 55.875, validation 94.138\n",
            "Epoch: 15/50 - Perplexity: training 51.560, validation 95.064\n",
            "Epoch: 16/50 - Perplexity: training 47.353, validation 96.134\n",
            "Epoch: 17/50 - Perplexity: training 43.549, validation 97.064\n",
            "Epoch: 18/50 - Perplexity: training 40.706, validation 98.434\n",
            "Epoch: 19/50 - Perplexity: training 37.719, validation 99.775\n",
            "Epoch: 20/50 - Perplexity: training 34.971, validation 100.593\n",
            "Epoch: 21/50 - Perplexity: training 32.556, validation 102.775\n",
            "Epoch: 22/50 - Perplexity: training 30.534, validation 104.955\n",
            "Epoch: 23/50 - Perplexity: training 28.581, validation 104.742\n",
            "Training complete !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instance = Train(model=model,\n",
        "                loss_fct=criterion,\n",
        "                optimizer=optimizer,\n",
        "                train_sequence=val_sequence,\n",
        "                val_sequence=None,\n",
        "                sequence_length=50,\n",
        "                batch_size=128,\n",
        "                epochs=13,\n",
        "                patience=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsLQ9M4736Bt",
        "outputId": "f3b43457-50de-4675-c0bb-8eea6d4827dc"
      },
      "id": "XsLQ9M4736Bt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train on validation data as well\n",
        "train_loss_of_val_data = instance.training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0bARbfB36Dt",
        "outputId": "7761b5dc-35a7-4fd3-b19c-70095a11bc13"
      },
      "id": "n0bARbfB36Dt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training..\n",
            "No validation data is used.\n",
            "Epoch: 1/13 - Perplexity: training 115.307\n",
            "Epoch: 2/13 - Perplexity: training 63.275\n",
            "Epoch: 3/13 - Perplexity: training 44.590\n",
            "Epoch: 4/13 - Perplexity: training 34.307\n",
            "Epoch: 5/13 - Perplexity: training 27.522\n",
            "Epoch: 6/13 - Perplexity: training 22.898\n",
            "Epoch: 7/13 - Perplexity: training 19.010\n",
            "Epoch: 8/13 - Perplexity: training 16.374\n",
            "Epoch: 9/13 - Perplexity: training 14.272\n",
            "Epoch: 10/13 - Perplexity: training 12.182\n",
            "Epoch: 11/13 - Perplexity: training 10.556\n",
            "Epoch: 12/13 - Perplexity: training 9.340\n",
            "Epoch: 13/13 - Perplexity: training 8.250\n",
            "Training complete !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_neural_model(test_sequence_of_integers = test_sequence,\n",
        "                        sequence_length = 50,\n",
        "                        model = model,\n",
        "                        loss_fct = nn.CrossEntropyLoss(),\n",
        "                        vocab_size = len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXb8QVJfDKMc",
        "outputId": "1aa7779f-5202-4d2e-ecb3-a037279024d4"
      },
      "id": "SXb8QVJfDKMc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "191.17134531847913"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3efuws_eJ27C"
      },
      "id": "3efuws_eJ27C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da2fd2ac",
      "metadata": {
        "id": "da2fd2ac"
      },
      "source": [
        "### Pre-Trained Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9d9c82",
      "metadata": {
        "id": "eb9d9c82"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db639c2",
      "metadata": {
        "id": "4db639c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a6c501",
      "metadata": {
        "id": "81a6c501"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "72762156",
      "metadata": {
        "id": "72762156"
      },
      "source": [
        "### Comparisons & Text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c9b5fe",
      "metadata": {
        "id": "b3c9b5fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f8ebf1f",
      "metadata": {
        "id": "4f8ebf1f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f9d6956a",
        "5812bcd0",
        "8d91ea29",
        "da2fd2ac",
        "72762156"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}